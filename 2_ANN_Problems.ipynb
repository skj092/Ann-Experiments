{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27251e20",
   "metadata": {},
   "source": [
    "# Aim : To Study the problems generally faced in training an ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419fb32",
   "metadata": {},
   "source": [
    "## Some problems we generally face while training a Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707dece7",
   "metadata": {},
   "source": [
    "### 1. Vaishing and Exploading Gradient Problems :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33fbec5",
   "metadata": {},
   "source": [
    "<img src=\"images/veg.jpg\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8a974",
   "metadata": {},
   "source": [
    "**Weight update formula of Gradient Discent is given by**\n",
    "$$W_{new} = W_{old}-\\eta\\frac{\\partial C}{ \\partial W_{old}}\\tag{i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7f5e4",
   "metadata": {},
   "source": [
    "`Cast Function`\n",
    "$$\\because C = y-y\\hat{}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc952e9",
   "metadata": {},
   "source": [
    "$$\\therefore \\frac{\\partial C}{\\partial w_{1}} = \\frac{\\partial C}{\\partial y\\hat{}} \\cdot \\frac{\\partial y\\hat{}}{\\partial a^3}\\cdot \\frac{\\partial a^3}{\\partial a^2}\\cdot \\frac{\\partial a^2}{\\partial a^1}\\cdot \\frac{\\partial a^1}{\\partial w_{1}}\\tag{ii}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730b7c8",
   "metadata": {},
   "source": [
    "$$\\therefore \\frac{\\partial C}{\\partial w_{2}} = \\frac{\\partial C}{\\partial y\\hat{}} \\cdot \\frac{\\partial y\\hat{}}{\\partial a^3}\\cdot \\frac{\\partial a^3}{\\partial a^2}\\cdot \\frac{\\partial a^2}{\\partial w_2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721dae9",
   "metadata": {},
   "source": [
    "$$\\therefore \\frac{\\partial C}{\\partial w_{3}} = \\frac{\\partial C}{\\partial y\\hat{}} \\cdot \\frac{\\partial y\\hat{}}{\\partial a^3}\\cdot \\frac{\\partial a^3}{\\partial w_{3}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a0a68",
   "metadata": {},
   "source": [
    "**As you can see the rate of change of cost function with respect of weights depends on : `the derivative of activation function`**\n",
    "\n",
    "**Let's look at the sigmoid activation funciton**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b4d79",
   "metadata": {},
   "source": [
    "$$Sigmoid \\left(x\\right) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ff9fb",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb83cf5",
   "metadata": {},
   "source": [
    "**Derivative of Sigmoid Function**\n",
    "$$Sigmoid^{`} \\left(x\\right) = \\frac{e^{-x}}{(1+e^{-x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854386f",
   "metadata": {},
   "source": [
    "<img src=\"images/dsigmoid.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15626088",
   "metadata": {},
   "source": [
    "`As you can see the derivative of sigmoid function is maximum at 0 and the maximum vaue is 0.25.`\n",
    "\n",
    "Have a look at equation (ii) now, if the values of 0.25 * 0.25 * 0.25 = 0.015625. This value after miltiply by learning becomes even lesser also decreases drastically as we increase the layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d858e",
   "metadata": {},
   "source": [
    "`Now if you look at equation (i), weight update becomes negligable as we increase the layer and we never rech to the solution` This is called as **Vanishing Gradient Problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ca3f0",
   "metadata": {},
   "source": [
    "**Exploading Gradient Problem** happens because of the weights. If all weight becomes heigher "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e0d21",
   "metadata": {},
   "source": [
    "### 2. Require Lots of data : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acec9e",
   "metadata": {},
   "source": [
    "To Train a neural network we require huge amound of data. To solve this problem we use `Transfer Learning`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603166f3",
   "metadata": {},
   "source": [
    "`Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82492c5",
   "metadata": {},
   "source": [
    "We will see the impact of tranfer learning on the later notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213f0a9",
   "metadata": {},
   "source": [
    "### 3. Slower Traning when Network is Large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3f458",
   "metadata": {},
   "source": [
    "If we increase number of layers in a neural network it increase parameter drastically and result in slower training rate. To solve this problem we use Better optimizer and Activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72fd07a",
   "metadata": {},
   "source": [
    "### 4. Risk of Overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539caef9",
   "metadata": {},
   "source": [
    "There are lots of reason a deep learning model overfit or we can say it always overfit. Here are some of the reason :\n",
    "    \n",
    "* Millions of trainaible parameter\n",
    "* Not Enough Data\n",
    "* Noicy or unwanted data\n",
    "\n",
    "To reduce the overfit there are different regularization methods and other technique we'll study in later notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
