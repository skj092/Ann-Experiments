{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e46cf8",
   "metadata": {},
   "source": [
    "# Aim : To Study The Affect Of Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858f88dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/06/14 09:45:58 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.python.keras import activations\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# downloading fashion_mnist data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0              \n",
    "\n",
    "\n",
    "import mlflow.tensorflow\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "initializer = tf.keras.initializers.glorot_normal\n",
    "activation = tf.keras.activations.tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86465e6",
   "metadata": {},
   "source": [
    "# without batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81fdffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "   3/1875 [..............................] - ETA: 4:35 - loss: 2.3288 - accuracy: 0.1771   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0489s). Check your callbacks.\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.4770 - accuracy: 0.8284\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3695 - accuracy: 0.8660\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3350 - accuracy: 0.8765\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3119 - accuracy: 0.8853\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2961 - accuracy: 0.8905\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2833 - accuracy: 0.8949\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2713 - accuracy: 0.8988\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2606 - accuracy: 0.9028\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2503 - accuracy: 0.9076\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2407 - accuracy: 0.9107\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\SONURA~1.JHA\\AppData\\Local\\Temp\\tmpn2wzpcx4\\model\\data\\model\\assets\n",
      "313/313 - 1s - loss: 0.3508 - accuracy: 0.8766\n",
      "test_loss 0.35076358914375305\n",
      "test_accuracy 0.8766000270843506\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(128, activation=activation, kernel_initializer=initializer),\n",
    "tf.keras.layers.Dense(10, kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "    print('test_loss', test_loss)\n",
    "    print('test_accuracy', test_acc)\n",
    "\n",
    "    mlflow.tensorflow.mlflow.log_metric('test_loss', test_loss)\n",
    "    mlflow.tensorflow.mlflow.log_metric('test_acc', test_acc)  \n",
    "    mlflow.tensorflow.mlflow.log_param('initializer', initializer)\n",
    "    mlflow.tensorflow.mlflow.log_param('activation', activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d7d50",
   "metadata": {},
   "source": [
    "# With BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a6a7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 105,418\n",
      "Trainable params: 103,594\n",
      "Non-trainable params: 1,824\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "   3/1875 [..............................] - ETA: 28:18 - loss: 2.7358 - accuracy: 0.1354WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_train_batch_end` time: 0.3016s). Check your callbacks.\n",
      "1875/1875 [==============================] - 10s 4ms/step - loss: 0.4793 - accuracy: 0.8297\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3835 - accuracy: 0.8628\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3558 - accuracy: 0.8721\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3405 - accuracy: 0.8751\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3248 - accuracy: 0.8796\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3147 - accuracy: 0.8851\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3029 - accuracy: 0.8884\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2973 - accuracy: 0.8908\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2895 - accuracy: 0.8931\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2863 - accuracy: 0.8935\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\SONURA~1.JHA\\AppData\\Local\\Temp\\tmpozlvwfz0\\model\\data\\model\\assets\n",
      "313/313 - 1s - loss: 0.3526 - accuracy: 0.8742\n",
      "test_loss 0.3526332676410675\n",
      "test_accuracy 0.8741999864578247\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation=activation, kernel_initializer=initializer),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "    print('test_loss', test_loss)\n",
    "    print('test_accuracy', test_acc)\n",
    "\n",
    "    mlflow.tensorflow.mlflow.log_metric('test_loss', test_loss)\n",
    "    mlflow.tensorflow.mlflow.log_metric('test_acc', test_acc)  \n",
    "    mlflow.tensorflow.mlflow.log_param('initializer', initializer)\n",
    "    mlflow.tensorflow.mlflow.log_param('activation', activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9a47b",
   "metadata": {},
   "source": [
    "# Withoud BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1137c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "   3/1875 [..............................] - ETA: 13:17 - loss: 2.3254 - accuracy: 0.1771WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.1420s). Check your callbacks.\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4785 - accuracy: 0.8285\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3718 - accuracy: 0.8648\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3357 - accuracy: 0.8759\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3135 - accuracy: 0.8841\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2936 - accuracy: 0.8905\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2801 - accuracy: 0.8957\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2696 - accuracy: 0.8996\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2599 - accuracy: 0.9035\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2505 - accuracy: 0.9061\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2420 - accuracy: 0.9091\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2327 - accuracy: 0.9123\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2277 - accuracy: 0.9146\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2218 - accuracy: 0.9172\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2139 - accuracy: 0.9201\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2084 - accuracy: 0.9220\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2031 - accuracy: 0.9240\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2026 - accuracy: 0.9240\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1962 - accuracy: 0.9270\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1908 - accuracy: 0.9285\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1871 - accuracy: 0.9292\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\SONURA~1.JHA\\AppData\\Local\\Temp\\tmpemfq8mh1\\model\\data\\model\\assets\n",
      "313/313 - 1s - loss: 0.3351 - accuracy: 0.8863\n",
      "test_loss 0.33514803647994995\n",
      "test_accuracy 0.8863000273704529\n"
     ]
    }
   ],
   "source": [
    "# deleting previous model\n",
    "del model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(128, activation=activation, kernel_initializer=initializer),\n",
    "tf.keras.layers.Dense(10, kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=20)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "    print('test_loss', test_loss)\n",
    "    print('test_accuracy', test_acc)\n",
    "\n",
    "    mlflow.tensorflow.mlflow.log_metric('test_loss', test_loss)\n",
    "    mlflow.tensorflow.mlflow.log_metric('test_acc', test_acc)  \n",
    "    mlflow.tensorflow.mlflow.log_param('initializer', initializer)\n",
    "    mlflow.tensorflow.mlflow.log_param('activation', activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3894b4f",
   "metadata": {},
   "source": [
    "# With BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eacd641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 105,418\n",
      "Trainable params: 103,594\n",
      "Non-trainable params: 1,824\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "   3/1875 [..............................] - ETA: 31:46 - loss: 2.4436 - accuracy: 0.2188   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.3389s). Check your callbacks.\n",
      "1875/1875 [==============================] - 10s 4ms/step - loss: 0.4766 - accuracy: 0.8283\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3865 - accuracy: 0.8594\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3608 - accuracy: 0.8670\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3362 - accuracy: 0.8772\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3265 - accuracy: 0.8797\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3143 - accuracy: 0.8845\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3062 - accuracy: 0.8858\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2971 - accuracy: 0.8909\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2927 - accuracy: 0.8915\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2871 - accuracy: 0.8951\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2784 - accuracy: 0.8963\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2754 - accuracy: 0.8972\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2701 - accuracy: 0.8991\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2664 - accuracy: 0.9013\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2629 - accuracy: 0.9021\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2574 - accuracy: 0.9041\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2562 - accuracy: 0.9057\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2552 - accuracy: 0.9051\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2492 - accuracy: 0.9060\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2457 - accuracy: 0.9078\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\SONURA~1.JHA\\AppData\\Local\\Temp\\tmpaofenqju\\model\\data\\model\\assets\n",
      "313/313 - 1s - loss: 0.3551 - accuracy: 0.8809\n",
      "test_loss 0.3550965487957001\n",
      "test_accuracy 0.8809000253677368\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation=activation, kernel_initializer=initializer),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=20)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "    print('test_loss', test_loss)\n",
    "    print('test_accuracy', test_acc)\n",
    "\n",
    "    mlflow.tensorflow.mlflow.log_metric('test_loss', test_loss)\n",
    "    mlflow.tensorflow.mlflow.log_metric('test_acc', test_acc)  \n",
    "    mlflow.tensorflow.mlflow.log_param('initializer', initializer)\n",
    "    mlflow.tensorflow.mlflow.log_param('activation', activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2f45e",
   "metadata": {},
   "source": [
    "# Observations : \n",
    "- Accuracy decreases with BatchNormalization may be because of the smaller network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba34522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
