{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa2934d",
   "metadata": {},
   "source": [
    "# Aim : To Study the impact of Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a517ff9",
   "metadata": {},
   "source": [
    "* A central problem in machine learning is how to make an algorithm that willperform well not just on the training data, but also on new inputs. \n",
    "* Many strategies used in machine learning are explicitly designed to reduce the test error, possiblyat the expense of increased training error. These strategies are known collectively as regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3266f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sonu.ramkumar.jha\\desktop\\experiments\\env\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\sonu.ramkumar.jha\\desktop\\experiments\\env\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "c:\\users\\sonu.ramkumar.jha\\desktop\\experiments\\env\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.python.keras import activations\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# downloading fashion_mnist data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0 \n",
    "\n",
    "activation = tf.keras.activations.relu\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(128, activation=activation),\n",
    "tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e0d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.4968 - accuracy: 0.8257\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3722 - accuracy: 0.8655\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3331 - accuracy: 0.8786\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3129 - accuracy: 0.8865: 0s - loss: 0.3\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2930 - accuracy: 0.8929\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2797 - accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2682 - accuracy: 0.9012\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2575 - accuracy: 0.9052\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2467 - accuracy: 0.9081\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2384 - accuracy: 0.9108\n",
      "313/313 - 1s - loss: 0.3582 - accuracy: 0.8748\n",
      "test_loss 0.3582005500793457\n",
      "test_accuracy 0.8748000264167786\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('test_loss', test_loss)\n",
    "print('test_accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f89f9",
   "metadata": {},
   "source": [
    "*Here loss on train dataset is `0.2384` and that of test dataset is `0.3582`. Which means model is overfitted.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a5b53",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008fce6",
   "metadata": {},
   "source": [
    "$$j\\hat{}\\left(  \\theta;X, y      \\right) = j\\left(  \\theta;X, y      \\right)+\\alpha \\ \\Omega\\left(\\theta \\right )\\tag{i}$$\\\n",
    "`Where`\n",
    "$$\\alpha: regularization \\ factor$$\\\n",
    "$$j\\hat{}\\left(  \\theta;X, y      \\right): Updated \\ Cast \\ Function$$\\\n",
    "$$j\\left(  \\theta;X, y      \\right): Cast \\ Function$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55a89c",
   "metadata": {},
   "source": [
    "## L1 Regulatization Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7aa9f3",
   "metadata": {},
   "source": [
    "$$\\ \\Omega\\left(\\theta \\right ) = \\left \\| W \\right \\|_1 = \\sum_{i}\\left |  w_i\\right |$$\n",
    "\n",
    "`Where`\n",
    "$$W : Model \\ Parameter$$ \\\n",
    "$$\\therefore j\\hat{}\\left(  \\theta;X, y      \\right) = j\\left(  \\theta;X, y      \\right)+\\alpha \\sum_{i}\\left |  w_i\\right |\\tag{from (i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3767b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 2.6841 - accuracy: 0.6450\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5893 - accuracy: 0.6867\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5271 - accuracy: 0.7065\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5036 - accuracy: 0.7155\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4944 - accuracy: 0.7172\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4865 - accuracy: 0.7204\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4814 - accuracy: 0.7228\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4781 - accuracy: 0.7263\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4733 - accuracy: 0.7273\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4707 - accuracy: 0.7291\n",
      "313/313 - 1s - loss: 1.4931 - accuracy: 0.7291\n",
      "test_loss 1.493071436882019\n",
      "test_accuracy 0.7290999889373779\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(128,  activation=activation, kernel_regularizer=tf.keras.regularizers.l1(0.01)),\n",
    "tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('test_loss', test_loss)\n",
    "print('test_accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab1b69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 2.6247 - accuracy: 0.6605\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5877 - accuracy: 0.7186\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.5304 - accuracy: 0.7365\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5114 - accuracy: 0.7387\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4970 - accuracy: 0.7386\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4868 - accuracy: 0.7400\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.4824 - accuracy: 0.7386\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4770 - accuracy: 0.7423\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4743 - accuracy: 0.7435\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4736 - accuracy: 0.7421\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4718 - accuracy: 0.7430\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4715 - accuracy: 0.7428\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4697 - accuracy: 0.7443\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4662 - accuracy: 0.7447\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4673 - accuracy: 0.7444\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4673 - accuracy: 0.7432\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4656 - accuracy: 0.7443\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4655 - accuracy: 0.7455\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4635 - accuracy: 0.7457\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4647 - accuracy: 0.7460\n",
      "313/313 - 0s - loss: 1.4851 - accuracy: 0.7431\n",
      "test_loss 1.4850802421569824\n",
      "test_accuracy 0.7430999875068665\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(128,  activation=activation, kernel_regularizer=tf.keras.regularizers.l1(0.01)),\n",
    "tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=20)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('test_loss', test_loss)\n",
    "print('test_accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef186e0f",
   "metadata": {},
   "source": [
    "L1 regularization makes model worse on training we well as testing dataset. Let's try different regularizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf804a",
   "metadata": {},
   "source": [
    "## L2 Regulatization Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadeadab",
   "metadata": {},
   "source": [
    "$$\\ \\Omega\\left(\\theta \\right ) = \\frac{1}{2}W^TW = \\frac{1}{2}\\sum_{i}\\left (  w_i\\right )^2$$\n",
    "\n",
    "`Where`\n",
    "$$W : Model \\ Parameter$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e151dcf",
   "metadata": {},
   "source": [
    "$$\\therefore j\\hat{}\\left(  \\theta;X, y      \\right) = j\\left(  \\theta;X, y      \\right)+\\frac{\\alpha}{2} \\sum_{i}\\left (  w_i\\right )^2\\tag{from (i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f071bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0314 - accuracy: 0.7859\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8465 - accuracy: 0.7977\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8380 - accuracy: 0.7954\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8315 - accuracy: 0.7987\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8250 - accuracy: 0.8010\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8242 - accuracy: 0.8010\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8209 - accuracy: 0.8025\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8165 - accuracy: 0.8056\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8150 - accuracy: 0.8057\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8112 - accuracy: 0.8080\n",
      "313/313 - 1s - loss: 0.8262 - accuracy: 0.8035\n",
      "test_loss 0.8261635899543762\n",
      "test_accuracy 0.8034999966621399\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(128,  activation=activation, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('test_loss', test_loss)\n",
    "print('test_accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca1ad3",
   "metadata": {},
   "source": [
    "L2 performs better than L1 as espected. But still our model is undertrain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e63b9",
   "metadata": {},
   "source": [
    "## Max Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22629747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.9542 - accuracy: 0.7843\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.8483 - accuracy: 0.7954\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8399 - accuracy: 0.7966\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8334 - accuracy: 0.7994\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8296 - accuracy: 0.8004\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8230 - accuracy: 0.8051\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8207 - accuracy: 0.8050\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8179 - accuracy: 0.8077\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8176 - accuracy: 0.8062\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8146 - accuracy: 0.8069\n",
      "313/313 - 0s - loss: 0.8189 - accuracy: 0.8036\n",
      "test_loss 0.8188563585281372\n",
      "test_accuracy 0.803600013256073\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(128,  activation=activation, kernel_regularizer=tf.keras.regularizers.l2(0.01), kernel_constraint=tf.keras.constraints.max_norm(1.)),\n",
    "tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.01), kernel_constraint=tf.keras.constraints.max_norm(1.))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('test_loss', test_loss)\n",
    "print('test_accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98d4b7",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38bb766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6781 - accuracy: 0.7525\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5262 - accuracy: 0.8074\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4936 - accuracy: 0.8193\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4762 - accuracy: 0.8236\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4668 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4573 - accuracy: 0.8300\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4509 - accuracy: 0.8326\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4427 - accuracy: 0.8355\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4400 - accuracy: 0.8376\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4338 - accuracy: 0.8378\n",
      "313/313 - 0s - loss: 0.3818 - accuracy: 0.8593\n",
      "test_loss 0.38183754682540894\n",
      "test_accuracy 0.8593000173568726\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dropout(0.4),\n",
    "tf.keras.layers.Dense(128, activation=activation),\n",
    "tf.keras.layers.Dropout(0.4),\n",
    "tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('test_loss', test_loss)\n",
    "print('test_accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1c360",
   "metadata": {},
   "source": [
    "Dropout performs best amoung all the other regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744e670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
